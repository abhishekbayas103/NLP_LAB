{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKoq0jP1Y2t5",
        "outputId": "5c37b117-de92-4567-930c-61c42a6dee91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn gensim nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "corpus = [\n",
        "    \"I love NLP\",\n",
        "    \"I love coding\",\n",
        "    \"I love NLP and coding\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "df_bow = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "print(\"--- Bag of Words (Count) ---\")\n",
        "print(df_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "malKbVdRZAJe",
        "outputId": "8f970b8c-57b3-4d6a-948c-1821a60ef08a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bag of Words (Count) ---\n",
            "   and  coding  love  nlp\n",
            "0    0       0     1    1\n",
            "1    0       1     1    0\n",
            "2    1       1     1    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_vectorizer = TfidfVectorizer(use_idf=False, norm='l1')\n",
        "X_norm = tf_vectorizer.fit_transform(corpus)\n",
        "df_norm = pd.DataFrame(X_norm.toarray(), columns=tf_vectorizer.get_feature_names_out())\n",
        "print(\"\\n--- Normalized Counts (Term Frequency) ---\")\n",
        "print(df_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emM1QwQ8ZEaw",
        "outputId": "81b6ce39-525f-468b-bc1a-0cb9a4903173"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Normalized Counts (Term Frequency) ---\n",
            "    and  coding  love   nlp\n",
            "0  0.00    0.00  0.50  0.50\n",
            "1  0.00    0.50  0.50  0.00\n",
            "2  0.25    0.25  0.25  0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
        "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "print(\"\\n--- TF-IDF Matrix ---\")\n",
        "print(df_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecgyefoJZIxI",
        "outputId": "414e115c-0bb3-45ee-dcaa-d129486086fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TF-IDF Matrix ---\n",
            "        and    coding      love       nlp\n",
            "0  0.000000  0.000000  0.613356  0.789807\n",
            "1  0.000000  0.789807  0.613356  0.000000\n",
            "2  0.631745  0.480458  0.373119  0.480458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "corpus = [\n",
        "    \"I love NLP\",\n",
        "    \"I love coding\",\n",
        "    \"I love NLP and coding\"\n",
        "]\n",
        "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "print(\"Tokens:\", tokenized_corpus)\n",
        "model = Word2Vec(sentences=tokenized_corpus, vector_size=10, window=2, min_count=1, workers=4)\n",
        "word_vector = model.wv['coding']\n",
        "print(\"\\nVector for 'coding':\", word_vector)\n",
        "\n",
        "similarity = model.wv.similarity('nlp', 'coding')\n",
        "print(f\"Similarity between 'nlp' and 'coding': {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtQrXOE3Zy-O",
        "outputId": "56577a62-a894-4b53-811c-7ed5c3ead719"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: [['i', 'love', 'nlp'], ['i', 'love', 'coding'], ['i', 'love', 'nlp', 'and', 'coding']]\n",
            "\n",
            "Vector for 'coding': [ 0.07311766  0.05070262  0.06757693  0.00762866  0.06350891 -0.03405366\n",
            " -0.00946401  0.05768573 -0.07521638 -0.03936104]\n",
            "Similarity between 'nlp' and 'coding': -0.1055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}